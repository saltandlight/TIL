# 17. 하이브

페이스북은 자사의 데이터웨어하우스에 하이브 이용하고 있다고 발표함.

페타바이트의 데이터를 하이브로 처리하고 있었음.

부트스트랩은 트위터 애들이 만든 것.

## 17.1 하이브 아키텍처

- 메타스토어: 

  우리가 하둡에 데이터를 저장할 구조를 심어놓는 곳

## 17.2 하이브 설치

MariaDB랑 하이브 연동

버전에 민감함.

hive-site.xml: 메타데이터를 어디에 저장할거냐? 를 해주는 configuration

```linux
schematool -initSchema -dbType mysql
hive
exit

false


<property>
  <name>hive.cli.print.header</name>
</property>

hive
select * from HDI;
exit;
```

하이브-> mapreduce 만들어짐-> jobtracker가 tasktracker에게 명령 

## 17.3 하이브 QL

SQL과 거의 유사함. 

```sql
cd
mkdir data
cd data
wget http://stat-computing.org/dataexpo/2009/2006.csv.bz2
wget http://stat-computing.org/dataexpo/2009/2007.csv.bz2
wget http://stat-computing.org/dataexpo/2009/2008.csv.bz2
bzip2 -kd 2006.csv.bz2
bzip2 -kd 2007.csv.bz2
bzip2 -kd 2008.csv.bz2



CREATE TABLE airline_delay(
Year INT,
MONTH INT,
DayofMonth INT,
DayofWeek INT,
DepTime INT,
CRSDepTime INT,
ArrTime INT,
CRSArrTime INT,
UniqueCarrier STRING,
FlightNum INT,
TailNum STRING,
ActualElapsedTime INT,
CRSElapsedTime INT,
AirTime INT,
ArrDelay INT,
DepDelay INT,
Origin STRING,
Dest STRING,
Distance INT,
TaxiIn INT,
TaxiOut INT,
Cancelled INT,
CancellationCode STRING
COMMENT 'A = carrier, B = weather, C = NAS, D = security',
Diverted INT COMMENT '1 = yes, 0 = no',
CarrierDelay STRING,
WeatherDelay STRING,
NASDelay STRING,
SecurityDelay STRING,
LateAircraftDelay STRING)
COMMENT 'TEST DATA'
PARTITIONED BY (delayYear INT)
ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '\n'
    STORED AS TEXTFILE;
//','로 컬럼 구분
//엔터로 구분

LOAD DATA LOCAL INPATH '/root/data/2006.csv'
OVERWRITE INTO TABLE airline_delay
PARTITION (delayYear='2006');

LOAD DATA LOCAL INPATH '/root/data/2007.csv'
OVERWRITE INTO TABLE airline_delay
PARTITION (delayYear='2007');

LOAD DATA LOCAL INPATH '/root/data/2008.csv'
OVERWRITE INTO TABLE airline_delay
PARTITION (delayYear='2008');
//delayyear가 2008인 애를 골라서 넣을거야~
//partition으로 나누면 빠르게 검색 가능
//년도별로 읽기가 가능해짐.
//이 이름으로 폴더를 만들어서 Partition할 거야~ 라는 뜻

select month, avg(ArrDelay), avg(DepDelay) from airline_delay
where delayYear='2006'
group by Month;

```

- SQL과의 차이점

  1. 하둡 파일 시스템에 데이터가 저장됨. HDFS가 한 번 저장한 파일은 수정할 수 없음

     -> UPDATE와 DELETE를 사용 못함.

     -> 같은 이유로 INSERT도 비어있는 테이블에 입력하거나 이미 입력된 데이터를 덮어 쓰는 경우에만 가능

  2. SQL은 서브쿼리 사용 가능하지만 하이브 QL은 FROM절에서만 서브쿼리 사용 가능함.

     ex)시카고에 근무하던 직원 중~~ 

  3. SQL의 뷰는 업데이트 가능. 하이브 QL의 뷰는 읽기전용

  4. SELECT 문 사용 시 HAVING 절 사용 안 함

  5. 저장 프로시저를 지원하지 않음. -> 대신 맵리듀스 스크립트 실행가능

### 17.3.1 테이블 생성

메타스토어

- 하이브 칼럼 타입

  - TINYUNT 	1바이트 정수
  - SAMLLINT      2바이트 정수
  - INT                  4바이트 정수
  - ...

- ALTER TABLE 이용해서 테이블 수정 가능

  테이블 삭제하고 싶으면 Drop table하면 됨.

- DROP TABLE display_statics

  -> 메타스토어 데이터베이스에 저장된 테이블과 HDFS에 저장된 데이터가 모두 삭제됨.

### 17.3.3 집계 함수

- COUNT(1), COUNT(*)        전체 데이터 건수 반환
- COUNT(DISTINCT 칼럼)    유일한 칼럼값의 건수를 반환. 

### 17.3.4 조인

- ON join임 (ANSI sql로 함)
- ​

## 17.4 파티션 레이블

3가지 방법

- LOAD DATA  명령어
- INSERT INTO TABLE 구문
- INSERT OVERWRITE TABLE 구문

INSERT OVERWRITE를 쓰는 것이 권고사항(이렇게 안 하면 복사됨...)

원 데이터 -> select -> insert도 가능

```sql
INSERT OVERWRITE airline_delay_raw PARTITION (delayyear='2007')
SELECT * 
FROM airline_delay
WHERE year=2007;

select month, avg(ArrDelay), avg(DepDelay) 
from airline_delay
where delayYear='2006'
group by Month;

```

order by보다 조금 빠르게 정렬할 수 있는 게 sort by

clustered by도 sort by와 동일함. 



ws

로그 찍는 거 

Spring MVC에서 동작했던 것을 로그 찍고 

하이브 통해서 하둡시스템ㅇ ㅔ넣기

요청햇을 때 hiveserver2에게 데이터를 달라고  함

맵리듀스가 돌음

로그는 저장 

요청 시 하이브에게 요청한 맵리듀스 가 돌아가서

json으로 결과 쌓고 하이차트로 차트 그려ㅑ줌

------------------

crontab과 shell scripts 이용

-> 하둡에 집어넣기



완전분산모드로 돌려서 진행 



airline data는 우리가 쌓은 로그는 아님, 

데이터가 큼...

분석 내용을 어떤 식으로 chart를 뿌려줄 것인가에 대한 전략 필요

로그 데이터는 요청을 하면 바로 나오지만

airline 이 아이는 너무 많아...

어떻게 해서 요청해서 보여줄 것인가(내일)





하둡 설치~~ 정리해놓은 것들 portfolio 에  append

깃허브 언제 한번 싹 정리하기..!

aws 등록하기 

터미널로 접속해서 파일 다운로드 -



시스템 아키텍처가 제일 중요함.

어떤환경에서 했는지 

mariadb 등등 설치했던 것 정리하기

필요한 jar파일 





- 오라클 연동은 그냥 두는 건지?
- ​