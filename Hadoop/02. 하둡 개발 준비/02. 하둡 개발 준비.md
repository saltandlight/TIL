# 02. 하둡 개발 준비

## 2.1 실행모드 결정

- 독립실행(Standalone) 모드:

  하나의 하둡만 실행시킴, 확장도 안 됨 

  완벽한 세팅은 아님 

- 가상 분산(Pseudo-distributed) 모드: 하나의 컴퓨터 안에 하나의 하둡만 설치, 향후 여

  ​                                                          러 서버와 연동 -> 확장 가능

- 완전 분산

​         **그림: 가상분산 모드**

![cap3](cap3.PNG)

- NameNode: 이 데이터 넣을게~ 하고 요청이 들어가면 세 대에 쪼개서 넣음. 

  ​                 데이터 끄집어낼래~ 하고 요청이 들어가면 각각의 데이터노드의 데이터를 취합해서 끄집어냄  

  ​                 **외부에서 빅데이터 환경으로 들어올 때 이 곳을 통해서 들어옴.**

  ​                 **-> Port가 있음(9000)**

- DataNode: 데이터가 저장되는 곳

- 여기서는 parity 검사를 하지 않음(똑같은 아이를 여러 개 복제함)

  -> 어느 하나의 서버가 망가져도 클론에 의해서 복구가능함. 

- Secondary NameNode: NameNode가 죽었다고 가정하자~ -> secondary namenode가 백업하고 있던 데이터를 새로운  namenode에 넣어줌.

## 2.2 리눅스 서버 준비

- client.jar도 갖다놓기 
- ssh-keygen -t dsa -P 
- //중간에 password 물어보는 거 안 하게 하려고 하는 것

## 2.3 하둡 다운로드

## 2.4 하둡 실행 계정 생성

루트 계정으로 하고 있음.

## 2.5 호스트 파일 수정

**SSH:**

```ssh
SSH(Secure Shell)란 네트워크 상의 다른 컴퓨터에 로그인하거나 원격 시스템에서 명령을 실행하고 다른 시스템으로 파일을 복사할 수 있게 해주는 응용 프로토콜이나 응용 프로그램 또는 그 프로토콜을 가리킴. 기존의 rsh, rlogin, telnet 등을 대체하기 위해 설계됨
```

etc/hosts에 다 세팅함.

## 2.6 인코딩 설정 방식

UTF-8로 통일함. 

이유: 영어나 한글을 잘 사용하기 위함. 

## 2.7 자바 설치

## 2.8 SSH 설정

패스워드를 물어보지 않게 하려고 이 작업을 진행함. 

내가 가진(생성한) public key를 다른 서버에 복사해서 넣어줌.

->다른 서버에 자유롭게 왔다갔다 할 수 있음.

공개키는 사용자 계정의 홈 디렉터리의 .ssh 폴더에 생성됨.

생성된 공개키를 ssh-copy-id 명령어를 이용해서 다른 서버에 복사 -> ssh-copy-id 명령어는 대상 서버의 .ssh 디렉터리 안에 있는 authrorized_keys 파일에 공개키를 입력

-> 다음과 같은 형식으로 실행

```linux
[root@hadoopserver1 ~]# ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
Generating public/private dsa key pair.
Your identification has been saved in /root/.ssh/id_dsa.
Your public key has been saved in /root/.ssh/id_dsa.pub.
The key fingerprint is:
f9:ea:14:e6:ef:04:23:21:d4:75:7f:3a:92:2b:4c:fb root@hadoopserver1
The key's randomart image is:
+--[ DSA 1024]----+
|    .. .. .      |
|   .  .  . .     |
|    . .     . .  |
|     . . . . o   |
|      . S o o    |
|       * * o .   |
|        * +      |
|       . *       |
|       .o.E      |
+-----------------+
[root@hadoopserver1 ~]# ls -a
.              .bashrc   .esd_auth       .swt             공개      서식
..             .cache    .local          .tcshrc          다운로드  음악
.ICEauthority  .config   .mozilla        anaconda-ks.cfg  문서
.bash_history  .cshrc    .mysql_history  bamboologs       바탕화면
.bash_logout   .dbus     .p2             file             비디오
.bash_profile  .eclipse  .ssh            shell            사진
[root@hadoopserver1 ~]# cd .ssh
[root@hadoopserver1 .ssh]# ls
id_dsa  id_dsa.pub  known_hosts
[root@hadoopserver1 .ssh]# more id_dsa
-----BEGIN DSA PRIVATE KEY-----
MIIBuwIBAAKBgQCydKP5Tk31EsrdIZVsv/RpQkoZTUrGFMdzSOc7OiF6uCAn5X95
0OcSvA+GXfqmo6tf0nJNVq47OcFmDbb/VZ7yOFIO9HfIlX884pHMXz9lcQjEbn2U
CxtdZ+ALEmbK2kYLpWnmCjjC6ppySjTyl7MqBn1Z98BLA5GYu+FEjuDcrwIVALmr
C2naMywMVBA4ZjVoigKh8S/DAoGAAVYKRMF/Y8qXdX1Km8Ky394ycFX6oOtyDAFk
FRQYTED3DUpiUQQP8fOhNOfNxWE6nylC4OnCCRvOTJOmMrVciyy8OxOrYjQr3nwZ
P6X6FvNHAkDo+APx6gFC66YP5rsw8ZZYquPW1OJCtrptCrzDGzyr1/WGOjkS4a5+
p06U2WwCgYAT3JOXnPO8uBunC/obnRSBGhqxe/0oC461FoBGDDfvp/teIOd1kh9p
swYtD4zlfTB44ZAeg5ds3H1omLK9fRpNzcJCx6nsEfsaODFsIsRTR/FIjsdAvQL/
oEHkgzrsTPUi0lLJPziUKmIrE0UQoPAgVVzBJ71WchjbkViIoG99ogIVAIUVDVN1
c7/7wxHqgfHz1QrjitdV
-----END DSA PRIVATE KEY-----
[root@hadoopserver1 .ssh]# more id_pub
id_pub: 그런 파일이나 디렉터리가 없습니다
[root@hadoopserver1 .ssh]# ls
id_dsa  id_dsa.pub  known_hosts
[root@hadoopserver1 .ssh]# cat id_dsa.pub >> authorized_keys
[root@hadoopserver1 .ssh]# ls
authorized_keys  id_dsa  id_dsa.pub  known_hosts
[root@hadoopserver1 .ssh]# cd
[root@hadoopserver1 ~]# ssh hadoopserver1
Last login: Mon Aug  5 14:03:17 2019 from hadoopserver1
```

나중에 다른 컴퓨터에 들어갈 때도 키를 물어봄

## 2.9 하둡 압축 파일 풀기

## 2.10 하둡 환경설정 파일 수정

- hadoop-env.sh 
  - JAVA_HOME 설정함. 
- masters: 보조 네임노드를 실행할 서버가 무엇이다~~ 해주는 애
- slaves: 데이터 노드는 누구이다~ 기입해주는 애 
- firewall 중지
- 옵션
  - HADOOP_CLASSPATH: 
  - HADOOP_HEAPSIZE
  - HADOOP_LOG_DIR
  - HADOOP_SLAVES: 데이터 노드가 등록된 파일 경로를 지정
  - HADOOP_MASTER: 보조 네임노드가 등록된 파일 경로를 지정

```linux 
systemctl disable firewalld 
```

- conf/core-site.xml 수정: 공통적으로 사용할 환경 정보 

```linux
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<property>
  <name>fs.default.name</name>
  <value>hdfs://localhost:9000</value>
</property>
<property>
  <name>dfs.tmp.dir</name>
  <value>/etc/hadoop-1.2.1/tmp</value>
</property>
</configuration>
```

- conf/hdfs-site.xml: 
  - namenode디렉터리; 어느 머신의 어떤 데이터 노드에 어떤 파일이 들어있따는 정보를 가지고 있음.
  - datanode: 데이터가 저장되는 곳

```linux
 
<configuration>
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
<property>
  <name>dfs.name.dir</name>
  <value>/usr/local/hadoop/name</value>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>/usr/local/hadoop/data</value>
</property>
<property>
  <name>dfs.webhdfs.enabled</name>
  <value>true</value>
</property>
</configuration>
```

- conf/hdfs-site.xml

  : 외부로 접근하는 것 세팅해줌.

``` linux
 
<configuration>
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
<property>
  <name>dfs.name.dir</name>
  <value>/usr/local/hadoop/name</value>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>/usr/local/hadoop/data</value>
</property>
<property>
  <name>dfs.webhdfs.enabled</name>
  <value>true</value>
</property>
</configuration>
```

- conf/mapred-site.xml
  - jobtracker: 분석에 대한 요청 받음 -> tasktracker에게 일하라고 명령함. 
  - tasktracker: 일 처리함. 

```linux
<configuration>
<property>
  <name>mapred.job.tracker</name>
  <value>localhost:9001</value>
</property>
</configuration>
```

- bashrc 수정

```linux
. /etc/hadooop-1.2.1/conf/hadoop-env.sh
```

- /etc/profile

```linux
# /etc/profile

# System wide environment and startup programs, for login setup
# Functions and aliases go in /etc/bashrc

# It's NOT a good idea to change this file unless you know what you
# are doing. It's much better to create a custom.sh shell script in
# /etc/profile.d/ to make custom changes to your environment, as this
# will prevent the need for merging in future updates.

pathmunge () {
    case ":${PATH}:" in
        *:"$1":*)
            ;;
        *)
            if [ "$2" = "after" ] ; then
                PATH=$PATH:$1
            else
                PATH=$1:$PATH
            fi
    esac
}


if [ -x /usr/bin/id ]; then
    if [ -z "$EUID" ]; then
        # ksh workaround
        EUID=`id -u`
        UID=`id -ru`
    fi
    USER="`id -un`"
    LOGNAME=$USER
    MAIL="/var/spool/mail/$USER"
fi

# Path manipulation
if [ "$EUID" = "0" ]; then
    pathmunge /usr/sbin
    pathmunge /usr/local/sbin
else
    pathmunge /usr/local/sbin after
    pathmunge /usr/sbin after
fi

HOSTNAME=`/usr/bin/hostname 2>/dev/null`
HISTSIZE=1000
if [ "$HISTCONTROL" = "ignorespace" ] ; then
    export HISTCONTROL=ignoreboth
else
    export HISTCONTROL=ignoredups
fi


JAVA_HOME=/etc/jdk1.8
export JAVA_HOME
CLASSPATH=$JAVA_HOME/lib
export CLASSPATH
 
ECLIPSE_HOME=/etc/eclipse
export ECLIPSE_HOME
 
 
TOMCAT_HOME=/etc/tomcat
export TOMCAT_HOME

HADOOP_HOME=/etc/hadoop-1.2.1
PATH=.:$JAVA_HOME/bin:$TOMCAT_HOME/bin:$HADOOP_HOME/bin:$PATH

export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL

# By default, we want umask to get set. This sets it for login shell
# Current threshold for system reserved uid/gids is 200
# You could check uidgid reservation validity in
# /usr/share/doc/setup-*/uidgid file
if [ $UID -gt 199 ] && [ "`id -gn`" = "`id -un`" ]; then
    umask 002
else
    umask 022
fi

for i in /etc/profile.d/*.sh ; do
    if [ -r "$i" ]; then
        if [ "${-#*i}" != "$-" ]; then 
            . "$i"
        else
            . "$i" >/dev/null
        fi
    fi
done

unset i
unset -f pathmunge
```

- format

```linux
hadoop namenode -format
```

- start-all.sh
- jps

```linux 
[root@hadoopserver1 hadoop-1.2.1]# jps
5155 SecondaryNameNode
2451 NameNode
5337 TaskTracker
5018 DataNode
2733 JobTracker
5550 Jps
```

디렉터리 생성되었는지 확인하기 

### 2.10.2 masters 수정

masters 파일에는 보조네임노드를 실행할 서버를 설정함. 2개 이상의 보조 네임 노드를 설정 가능, 한 줄에 하나씩 서버를 기재하면 됨.

### 2.10.3 slaves 수정

데이터 노드를 실행할 서버를 설정

### 2.10.4 core-site.xml  수정

### 2.10.5 hdfs-site.xml 수정

한 번 들어갈 떄 3개가 복제해서 들어감.

secondary name에 대한 정보를 저장함. 데이터가 어디에 들어갈 것인지, 웹에서 돌아간다는 것을 세팅해줌.

jobtracker가 외부에서 들어올 때 요청 받으면 50090포트 열음

namenode에서 모든 수정작업이 완료되면 하둡을 tar로 묶어서 02 03 04번에 다 복사해줌.(모든 데이터노드 서버에 복사)

tar풀면 모든 서버에는 namenode에서 세팅한 하둡 프로그램이 각각의 컴퓨터에 세팅됨.

## 2.11 하둡 실행

``` linux
./bin/hadoop namenode -format
```

1. ssh 활성화(hadoop1)

   ```linux
   ssh-keygen -t dsa -P '' -f  ~/.ssh/id_dsa
   cd .ssh
   ls
   cat id_dsa.pub > authorized_keys
   ```

2. scp  

   bashrc에 추가

   . /etc/hadoop-1.2.1/conf/hadoop-env.sh

   hadoop namenode -format

   start-all.sh

   //hadoop2, 3, 4 다  떠야 함 .

   systemctl disable firewall 

   stop-all.sh

   systemctl stop firewalld(4대 모두 다 해주기 )

   systemctl disable firewalld

   cd etc

   tar cvfz hadoop.tar.gz hadoop-1.2.1

   scp 해주고 각각의 하둡2,3,4에 해주기

   ssh root@hadoop2 "cd /etc;tar xvfz hadoop.tar.gz;rm -rf hadoop.tar.gz"

   ssh root@hadoop3 "cd /etc;tar xvfz hadoop.tar.gz;rm -rf hadoop.tar.gz"

   ssh root@hadoop4 "cd /etc;tar xvfz hadoop.tar.gz;rm -rf hadoop.tar.gz"

   scp authorized_keys root@hadoop2:~/.ssh/authorized_keys

![cap4](cap4.PNG)

``` memo
기업은AWS,IBM, MS의 서비스를 이용하고 싶음
그런데서비스의 한계가 있음
; 트랜잭션이얼마였습니다~~ 이 정도

회사가하는 역할: 필요한 클라우드 환경을 컨설팅하는 것. 
기업은 클라우드 환경 구축해줌. 
기본적으로 하둡이 제공하는 UI를 다듬어서 판다. 
여러가지 분석에 대한 것들도 기업이 해줌

IT 비즈니스의동향: 클라우드 환경 서비스를 다들 하기를 원함. 그런데 기존 글로벌 기업들의 서비스가 독보적임. 
(해외에서도 offer가 들어옴)

기업에 서비스를 해주는 비즈니스 
그런데 국내에서는 팔아먹을 곳이 없다.
다음이나 네이버는 확실히 빅데이터가 필요하긴 함. 
```

![cap5](cap5.PNG)

```메모
Heartbeat 신호를 주고 받음
-> 생사여부 확인 
datenode 가 namenode에게 heartbeat를 보냄(삐삐삐 slave 살아있다...삐삐삐 뭐 이런 뜻)
하트비트 내용: 디스크 가용 공간정보, 데이터 이동, 적재량 

Hadoop1을 포맷하면 Hadoop2, hadoop3, hadoop4 포맷됨

Start-all.sh 실행
-> hadoop2, hadoop3, hadoop4도 실행됨.

Namenode와 jobtracker가 slaves들을 관리함.
```
